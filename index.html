<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Susu Sun</title>

    <meta name="author" content="Susu Sun">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <link rel="stylesheet" type="text/css" href="styles_responsive.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;"> 
                  Susu Sun
                <p>
		I’m a PhD student in the <a href="https://baumgach.github.io/med-AI-website/">Medical AI Lab</a> at the University of Tübingen, supervised by <a href="https://baumgach.github.io/med-AI-website/people/baumgartner-christian/">Prof. Christian F. Baumgartner</a> .
		I’m currently visiting the <a href="https://med.stanford.edu/mimi.html">Machine Intelligence for Medical Imaging Lab</a> at Stanford University, hosted by <a href="https://profiles.stanford.edu/akshay-chaudhari">Dr. Akshay Chaudhari</a> .
		Previously, I visited the <a href="https://www.computationalpathologygroup.eu/">Computational Pathology Group</a> at Radboud UMC, hosted by <a href="https://www.computationalpathologygroup.eu/members/geert-litjens/">Prof. Geert Litjens</a> .
		
    <p>My research focuses on <b>interpretable machine learning for medical image analysis</b>, with the goal of building more transparent and trustworthy systems for clinical applications. My PhD is supported by the Carl Zeiss Foundation, the Cluster of Excellence “Machine Learning for Science”, and the International Max Planck Research School for Intelligent Systems (IMPRS-IS).</p>
                </p>
                <p style="text-align:center">
                  <a href="mailto:susu.sun@uni-tuebingen.de"><i class="fa fa-envelope-square"></i>&nbsp&nbspEmail</a> &nbsp/&nbsp
                  <a href="https://scholar.google.com/citations?user=cyGvnh8AAAAJ&hl=en" target="_blank" rel="noopener noreferrer"><i class="fa fa-google"></i>&nbsp&nbspGoogle Scholar</a> &nbsp/&nbsp
                  <a href="https://www.linkedin.com/in/susu-sun-a31b25248/" target="_blank" rel="noopener noreferrer"><i class="fa fa-linkedin"></i>&nbsp&nbspLinkedIn</a> &nbsp/&nbsp
                  <a href="https://github.com/ss-sun/" target="_blank" rel="noopener noreferrer"><i class="fa fa-github"></i>&nbsp&nbspGithub</a> 
                </p>
              </td>
              <td style="padding:2.5%;width:37%;max-width:37%">
                <a href="images/susu/susu_avatar.png"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/susu/susu_avatar.png" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Research</h2>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>




<!-- <tr onmouseout="radmesh_stop()" onmouseover="radmesh_start()" bgcolor="#ffffd0"> -->
  <!-- <td style="padding:16px;width:20%;vertical-align:middle">
    <div class="one">
      <div class="two" id='radmesh_image'>
        <img src='images/radmesh_after.jpg' width=100%>
      </div>
      <img src='images/radmesh_before.jpg' width=100%>
    </div>
    <script type="text/javascript">
      function radmesh_start() {
        document.getElementById('radmesh_image').style.opacity = "1";
      }

      function radmesh_stop() {
        document.getElementById('radmesh_image').style.opacity = "0";
      }
      radmesh_stop()
    </script>
  </td> -->
  <!-- <td style="padding:8px;width:80%;vertical-align:middle">
    <a href="https://half-potato.gitlab.io/rm/">
      <span class="papertitle">Prototype-Based Multiple Instance Learning for Gigapixel Whole Slide Image Classification</span>
    </a>
    <br>
    <strong>Susu Sun</strong>,
    <a href="https://www.computationalpathologygroup.eu/members/dominique-van-midden/">Dominique van Midden</a>,
    <a href="https://www.computationalpathologygroup.eu/members/geert-litjens/">Geert Litjens</a>,
    <a href="https://baumgach.github.io/med-AI-website/people/baumgartner-christian/">Christian F Baumgartner</a>,
    <br>
    MICCAI, 2025
    <br>
    <div class="box-row">
      <div class="box">
        <a href="https://github.com/ss-sun/ProtoMIL"> <i class="fa fa-github"></i> Code</a>
      </div>
      <div class="box">
        <a href="https://arxiv.org/abs/2503.08384"><i class="fa fa-file-pdf-o"></i> arXiv</a>
      </div>
    </div>
    <p></p>
    <p>
	Parameterizing a scene with a Delaunay tetrahedralization and a neural field yields a scene representation that is accurate, fast to render, easy to edit, and backwards-compatible.
    </p>
  </td>
</tr> -->




<div class="container2">
  <div class="image2">
    <img src='images/susu/ProtoMIL.png' width:450; height="auto">
  </div>
  <div class="item text2">
    <a href="https://link.springer.com/chapter/10.1007/978-3-032-05185-1_49">
      <papertitle>Prototype-Based Multiple Instance Learning for Gigapixel Whole Slide Image Classification</papertitle>
      </a>
      <br>
      <strong>Susu Sun</strong>,
      <a href="https://www.computationalpathologygroup.eu/members/dominique-van-midden/">Dominique van Midden</a>,
      <a href="https://www.computationalpathologygroup.eu/members/geert-litjens/">Geert Litjens</a>,
      <a href="https://baumgach.github.io/med-AI-website/people/baumgartner-christian/">Christian F Baumgartner</a>,
      <br>
      MICCAI 2025 (Early acceptance)
      <br>

      <div class="box-row">
        <div class="box">
          <a href="https://github.com/ss-sun/ProtoMIL"> <i class="fa fa-github"></i> Code</a>
        </div>
        <div class="box">
          <a href="https://arxiv.org/abs/2503.08384"><i class="fa fa-file-pdf-o"></i> arXiv</a>
        </div>
      </div>

      <p></p>
      <p>
        ProtoMIL is an inherently interpretable MIL model for whole slide histopathology that learns human-understandable concepts with a sparse autoencoder, makes predictions as transparent linear combinations of these concepts, enables user intervention by editing concepts, and matches state-of-the-art accuracy while reducing reliance on spurious signals.      </p>
    </div>
  </div>


<div class="container2">
  <div class="image2">
    <img src='images/susu/Subgroup.png' width:450; height="auto">
  </div>
  <div class="item text2">
    <a href="https://link.springer.com/chapter/10.1007/978-3-032-05185-1_57">
      <papertitle>Subgroup Performance Analysis in Hidden Stratifications</papertitle>
    </a>
    <br>
    <a href="https://www.mlm-lab.ch/people/">Alceu Bissoto</a>,
    <a href="https://www.mlm-lab.ch/people/">Trung-Dung Hoang</a>,
    <a href="https://www.mlm-lab.ch/people/">Tim Flühmann</a>, 
    <strong>Susu Sun</strong>, 
    <a href="https://baumgach.github.io/med-AI-website/people/baumgartner-christian/">Christian F Baumgartner</a>, 
    <a href="https://www.mlm-lab.ch/people/">Lisa M Koch</a>
    <br>
    MICCAI 2025 (Early acceptance)
    <br>

    <div class="box-row">
      <div class="box">
        <a href="https://github.com/alceubissoto/hidden-subgroup-perf"><i class="fa fa-github"></i> Code</a>
      </div>
      <div class="box">
        <a href="https://arxiv.org/abs/2503.10382"><i class="fa fa-file-pdf-o"></i> arXiv</a>
      </div>
    </div>

    <p></p>
    <p>
    In this work, we show that unsupervised subgroup discovery from learned representations, paired with new evaluation strategies, can reveal hidden patient stratifications and larger performance disparities than metadata-based subgroup analysis for monitoring ML reliability in chest x-ray and skin lesion classification.
    </p>
  </div>
</div>


<div class="container2">
  <div class="image2">
    <img src='images/susu/ConceptMIL.png' width:450; height="auto">
  </div>
  <div class="item text2">
    <a href="https://arxiv.org/abs/2501.02922">
      <papertitle>Label-free Concept Based Multiple Instance Learning for Gigapixel Histopathology</papertitle>
      </a>
      <br>
      <strong>Susu Sun</strong>,
      <a href="https://www.computationalpathologygroup.eu/members/leslie-tessier/">Leslie Tessier</a>,
      <a href="https://www.computationalpathologygroup.eu/members/frederique-meeuwsen/">Frédérique Meeuwsen</a>,
      <a href="https://www.computationalpathologygroup.eu/members/clement-grisi/">Clément Grisi</a>,
      <a href="https://www.computationalpathologygroup.eu/members/dominique-van-midden/">Dominique van Midden</a>,
      <a href="https://www.computationalpathologygroup.eu/members/geert-litjens/">Geert Litjens</a>,
      <a href="https://baumgach.github.io/med-AI-website/people/baumgartner-christian/">Christian F Baumgartner</a>,
      <br>
      In major revision at IEEE Transactions on Medical Imaging
      <br>

      <div class="box-row">
        <div class="box">
          <a href="https://github.com/ss-sun/concept_MIL"> <i class="fa fa-github"></i> Code</a>
        </div>
        <div class="box">
          <a href="https://arxiv.org/abs/2501.02922"><i class="fa fa-file-pdf-o"></i> arXiv</a>
        </div>
      </div>

      <p></p>
      <p>
      Concept MIL is an inherently interpretable WSI classification method that uses a vision-language model to predict human-understandable pathology concepts from top-K patches and makes slide predictions as linear combinations of these concepts, achieving state-of-the-art performance without concept annotations while producing explanations aligned with pathologists.    </div>
</div>


<div class="container2">
    <div class="image2">
      <img src='images/susu/Attrinet_melba.png' width:450; height="auto">
    </div>
    <div class="item text2">
      <a href="https://www.melba-journal.org/papers/2025:028.html">
        <papertitle>Attri-Net: A Globally and Locally Inherently Interpretable Model for Multi-Label Classification Using Class-Specific Counterfactuals</papertitle>
        </a>
        <br>
        <strong>Susu Sun</strong>,
        <a href="https://baumgach.github.io/med-AI-website/people/woerner-stefano/">Stefano Woerner</a>,
        <a href="https://lme.tf.fau.de/person/maier/">Andreas Maier</a>,
        <a href="https://www.mlm-lab.ch/people/">Lisa M Koch</a>,
        <a href="https://baumgach.github.io/med-AI-website/people/baumgartner-christian/">Christian F Baumgartner</a>
        <br>
        Machine Learning for Biomedical Imaging Journal 2025
        <br>
  
        <div class="box-row">
          <div class="box">
            <a href="https://github.com/ss-sun/Attri-Net-V2"> <i class="fa fa-github"></i> Code</a>
          </div>
          <div class="box">
            <a href="https://arxiv.org/abs/2406.05477"><i class="fa fa-file-pdf-o"></i> arXiv</a>
          </div>
        </div>
  
        <p></p>
        <p>
        Attri-Net is an inherently interpretable multi-label medical classifier that generates class-specific attribution maps, classifies using logistic regression on those maps, and provides both local and global explanations aligned with clinical knowledge without sacrificing performance.      </div>
</div>
  

<div class="container2">
    <div class="image2">
      <img src='images/susu/right_for_wrong_reason.png' width:450; height="auto">
    </div>
      <div class="item text2">
        <a href="https://link.springer.com/chapter/10.1007/978-3-031-43895-0_40">
          <papertitle>Right for the wrong reason: Can interpretable ML techniques detect spurious correlations?</papertitle>
          </a>
          <br>
          <strong>Susu Sun</strong>,
          <a href="https://www.mlm-lab.ch/people/">Lisa M Koch</a>,
          <a href="https://baumgach.github.io/med-AI-website/people/baumgartner-christian/">Christian F Baumgartner</a>
          <br>
          MICCAI 2023
          <br>
    
          <div class="box-row">
            <div class="box">
              <a href="https://github.com/ss-sun/right-for-the-wrong-reason"> <i class="fa fa-github"></i> Code</a>
            </div>
            <div class="box">
              <a href="https://arxiv.org/abs/2307.12344"><i class="fa fa-file-pdf-o"></i> arXiv</a>
            </div>
          </div>
    
          <p></p>
          <p>
            We propose an evaluation framework for testing whether XAI methods can detect spurious correlations, and show on chest X-ray tasks with injected spuriouse signals that SHAP and the inherently interpretable Attri-Net most reliably identify faulty model reasoning. 
          </p>
      </div>
</div>



    <div class="container2">
      <div class="image2">
        <img src='images/susu/Attrinet_midl.png' width:450; height="auto">
      </div>
      <div class="item text2">
        <a href="https://arxiv.org/abs/2303.00500">
          <papertitle>Inherently Interpretable Multi-Label Classification Using Class-Specific Counterfactuals</papertitle>
          </a>
          <br>
          <strong>Susu Sun</strong>,
          <a href="https://baumgach.github.io/med-AI-website/people/woerner-stefano/">Stefano Woerner</a>,
          <a href="https://lme.tf.fau.de/person/maier/">Andreas Maier</a>,
          <a href="https://www.mlm-lab.ch/people/">Lisa M Koch</a>,
          <a href="https://baumgach.github.io/med-AI-website/people/baumgartner-christian/">Christian F Baumgartner</a>
          <br>
          MIDL 2023
          <br>
    
          <div class="box-row">
            <div class="box">
              <a href="https://github.com/ss-sun/Attri-Net"> <i class="fa fa-github"></i> Code</a>
            </div>
            <div class="box">
              <a href="https://arxiv.org/abs/2303.00500"><i class="fa fa-file-pdf-o"></i> arXiv</a>
            </div>
          </div>
    
          <p></p>
          <p>
          Attri-Net is an inherently interpretable multi-label chest X-ray classifier that uses counterfactual class-specific attribution maps plus logistic regression to deliver clinically consistent explanations while matching state-of-the-art performance and outperforming post-hoc methods in the multi-label setting.         </div>
      </div>


  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr>
      <td style="padding:16px;width:100%;vertical-align:middle">
        <h2>Invited Talks</h2>
        <ul>
          <li>2025.7: Concept-Based Interpretable Models for Histopathology. Online, hosted by <a href="https://medgift.hevs.ch/wordpress/team/adrien-depeursinge/">Prof. Dr Adrien Depeursinge</a></li>
          <li>2025.1: BuildingInherently Interpretable Models for Medical Image Analysis. Utrecht University, hosted by <a href="https://www.uu.nl/staff/WJdosSantosSilva1">Dr. Wilson Silva</a></li>
          <li>2023.9: Interpretable Machine Learning for Medical Image Analysis. Radboud University Medical Center, hosted by <a href="https://www.diagnijmegen.nl/people/bram-van-ginneken/">Prof. Bram van Ginneken</a></li>
      </td>
    </tr>
  </tbody></table>
  <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


  

    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr>
      <td style="padding:16px;width:100%;vertical-align:middle">
        <h2>Academic Service</h2>
        <ul>
          <li>Reviewer for IEEE TMI, MedIA, MIDL 2024-2026, MICCAI 2025, XAI4CV workshop at CVPR 2025, eXCV workshop at ECCV 2024, CaLM Workshop at NeurIPS 2024. iMIMIC workshops 2023-2024</li>
      </ul>
      </td>
    </tr>
  </tbody></table>
  <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr>
      <td style="padding:16px;width:100%;vertical-align:middle">
        <h2>Teaching</h2>
        <ul>
          <li>Master Thesis supervision: Evaluations of Interpretable Machine Learning Methods for Detecting Model’s Shortcut
            Learning Behavior in Medical Imaging. (University of Tübingen) WS23/24.</li>
          <li>Semester project supervision: Concept-based Classification for Mammography. (University of Tübingen) WS23/24.</li>
          <li>Teaching Assistent: Machine Learning for Medical Image Analysis Seminar (University of Tübingen) WS22/23.</li>
          <li>Teaching Assistent: Deep Learning Lecturer (University of Erlangen-Nuremberg) SS21.</li>
          <li>Teaching Assistent: Machine Learning in Signal Processing Lab Course (University of Erlangen-Nuremberg) WS20/21.</li>
      </ul>
      </td>
    </tr>
  </tbody></table>
  <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>




          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Template adapted from <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron</a> and <a href="https://ligengen.github.io/">Gen Li</a>. 
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>


